# The file to generate either MFCC or MMFCC feature is: make_MFCC_And_MMFCC2_features.m

The structure of this function file is as follows:

------------------------------------------------------------------------------
% This function is used to evaluate the features which is subsequently used
% by the ACORNS recognition systems, such as CM, DP-N Gram and NMF. Also,
% this can be used by standard HTK.
% It can generate either MFCC features or MMFCC features

% We need noisy features to test the robustness of recognizers. So, the routine adds the noise to the clean test speech
corpus data on-the-fly. Only, we need to specify the noise database path, noise type and SNR level. For clean testing,
choice of SNR should be very high, may be SNR=1000 (in dB).

% For training, noise is not added even though we choose noise database path, noise type and SNR level.


function O= make_MFCC_And_MMFCC2_features(input,WinLen,WinShift,SigInpFs,SigOprFs,MFCC_flag,MMFCC_flag,Dynamic_flag,CMVN_flag,NoiseType,SNR,NoiseDBPath,train_flag)

% input -> Input speech signal with sampl freq=44.1 kHz
% WinLen -> Window length in second 
% WinShift -> Window shift in second
% SigInpFs -> Sampling frequency (in Hz) of input speech signal (Default=44100)
% SigOprFs -> Sampling frequency (in Hz) of operating speech signal (Default=16000)
% MFCC_flag -> If set, then output feature = MFCC parameters. Otherwise put
% it off.
% MMFCC_flag -> If set, then output feature = MMFCC parameters. Otherwise put
% it off.
% Dynamic_flag -> If set, then output will be 39-dimensional feature of
% E+feature+Vel+Acc.
% CMVN_flag -> If set, then output feature will be Cepstrum Mean and
% Variance Normalized (CMVN). The CMVN is carried out in
% utterance-by-utterance basis (i.e. file-by-file).
% NoiseType -> This specifies the noise type to corrupt the test speech signal (babble, pink, volvo and white)
% SNR -> SNR in dB  (Choose SNR=1000 for clean testing)
% NoiseDBPath -> Specify the path of noise database directory

% O <- Feature. 12 dimensional if Dynamic_flag=0. Else, 39 dimensional if
% Dynamic_flag=1.




% Let us provide some details:


(1) Suppose that we desire for training the recognizers. Note that training is always using clean speech, but still we have to choose NoiseType, SNR and NoiseDBPath. Also, we want to use MMFCCs. The input to the functions will be:
 
input -> input signal of 44.1 kHz (ACORNS training speech files one-by-one)
train_flag=1;
NoiseDBPath='../MFCC&MMFCC2/NoiseX_16kHz/';  % Specify the path of noise database directory
NoiseType='babble';
SNR=1000; 
MFCC_flag=0;
MMFCC_flag=1;
Dynamic_flag=1;
CMVN_flag=1;                      
SigInpFs=44100;                  
SigOprFs=16000;                  
WinLen=0.032;                    % 32ms
WinShift=0.010;                  % 10 ms




(2) Now, suppose that we desire for clean testing of the recognizers. Also, we want to use MMFCCs. The input to the functions will be:
 
input -> input signal of 44.1 kHz (ACORNS testing speech files one-by-one)
train_flag=0;
NoiseDBPath='../MFCC&MMFCC2/NoiseX_16kHz/';  % Specify the path of noise database directory
NoiseType='babble';
SNR=1000;           % Choose a very high SNR (in dB), so that it can be considered as clean. choose SNR=1000.
MFCC_flag=0;
MMFCC_flag=1;
Dynamic_flag=1;
CMVN_flag=1;                      
SigInpFs=44100;                  
SigOprFs=16000;                  
WinLen=0.032;                    % 32ms
WinShift=0.010;                  % 10 ms




(3) Now, suppose that we desire for robust testing of the recognizers in presence of white noise at SNR=10 dB. 
Also, we want to use MMFCCs. The input to the functions will be:
 
input -> input signal of 44.1 kHz (ACORNS testing speech files one-by-one)
train_flag=0;
NoiseDBPath='../MFCC&MMFCC2/NoiseX_16kHz/';  % Specify the path of noise database directory
NoiseType='white';
SNR=10;           % Choose a very high SNR (in dB), so that it can be considered as clean. choose SNR=1000.
MFCC_flag=0;
MMFCC_flag=1;
Dynamic_flag=1;
CMVN_flag=1;                      
SigInpFs=44100;                  
SigOprFs=16000;                  
WinLen=0.032;                    % 32ms
WinShift=0.010;                  % 10 ms
 


% Please see the file 'htk_MFCC_And_MMFCC2_feature.m' which I use for generating and writing the features from input speech signal into as HTK format. This file is utterly important to see how the features are generated using 'make_MFCC_And_MMFCC2_features.m' function.